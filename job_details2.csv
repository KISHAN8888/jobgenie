,job_title,company,location,remote_work_allowed,job_description,job_details,company_details,required_experience_and_skills
0,Interesting Job Opportunity: Data Engineer - R/SQL/Python,HuQuo,"Gurugram, Haryana, India",False,"{'description': ""Job Responsibilities\n\n Emphasis on end-to-end delivery of analysis and guiding junior staff, contribute to how analytical approach is structured for specification of analysis Use variety of analytical tools (SQL/SAS, R/Python, Tableau/Power BI) for insight generation & enabling the client with data driven decision making Reformulate highly technical information into concise & understandable terms for presentations\n\nSkills Required\n\n Master's or bachelor's degree in math, statistics, economics, computer science or analytics related field from top-tier universities 2-7 years of consulting, analytics delivery experience Hands-on experience of analytics tools (SQL, R/Python) is a must Very strong analytical skills with the demonstrated ability to research & make decisions based on the day-to-day and complex customer problems\n\n(ref:hirist.tech)""}","{'employment_type': None, 'seniority_level': None, 'job_functions': [], 'industries': [], 'remote_work_allowed': False, 'job_description': {'description': ""Job Responsibilities\n\n Emphasis on end-to-end delivery of analysis and guiding junior staff, contribute to how analytical approach is structured for specification of analysis Use variety of analytical tools (SQL/SAS, R/Python, Tableau/Power BI) for insight generation & enabling the client with data driven decision making Reformulate highly technical information into concise & understandable terms for presentations\n\nSkills Required\n\n Master's or bachelor's degree in math, statistics, economics, computer science or analytics related field from top-tier universities 2-7 years of consulting, analytics delivery experience Hands-on experience of analytics tools (SQL, R/Python) is a must Very strong analytical skills with the demonstrated ability to research & make decisions based on the day-to-day and complex customer problems\n\n(ref:hirist.tech)""}, 'job_url': {'com.linkedin.voyager.jobs.OffsiteApply': {'applyStartersPreferenceVoid': False, 'companyApplyUrl': 'https://www.hirist.tech/j/data-engineer-rsqlpython-2-7-yrs-1352449.html?utm_source=LinkedIn&utm_medium=listing&utm_campaign=linkedin_apply_ref&ref=linkedin', 'inPageOffsiteApply': False}}}","{'company_name': 'HuQuo', 'company_url': 'https://www.linkedin.com/company/huquo-consulting-pvt.-ltd.'}","{'technical_skills': [], 'other_skills': [], 'soft_skills': []}"
1,Data Engineer: Data Platforms,IBM,"Bengaluru East, Karnataka, India",False,"{'description': ""Introduction\n\nIn this role, you'll work in one of our IBM Consulting Client Innovation Centers (Delivery Centers), where we deliver deep technical and industry expertise to a wide range of public and private sector clients around the world. Our delivery centers offer our clients locally based skills and technical expertise to drive innovation and adoption of new technology.\n\nA career in IBM Consulting is rooted by long-term relationships and close collaboration with clients across the globe.\n\nYou'll work with visionaries across multiple industries to improve the hybrid cloud and AI journey for the most innovative and valuable companies in the world. Your ability to accelerate impact and make meaningful change for your clients is enabled by our strategic partner ecosystem and our robust technology platforms across the IBM portfolio; including Software and Red Hat.\n\nCuriosity and a constant quest for knowledge serve as the foundation to success in IBM Consulting. In your role, you'll be encouraged to challenge the norm, investigate ideas outside of your role, and come up with creative solutions resulting in ground breaking impact for a wide network of clients. Our culture of evolution and empathy centers on long-term career growth and development opportunities in an environment that embraces your unique skills and experience.\n\nYour Role and Responsibilities\n\n\nUnderstand a data warehousing solution and able to work independently in such an environmentResponsible in Project development and delivery experience of a few good size projects\n\n\nRequired Technical and Professional Expertise\n\n\nFirst and most important – Sound understanding of data structures & SQL concepts and experience in writing complex SQL especially around OLAP systemsSound knowledge of the ETL tool like informatica, 5+ years of experience, Big Data technologies’ like Hadoop ecosystem, its various components, along with different tools including Spark, Hive, Sqoop,etc..In-depth knowledge of MPP/distributed systems\n\n\nPreferred Technical And Professional Expertise\n\n\nThe ability to write precise, scalable, and high-performance codeThe ability to write precise, scalable, and high-performance codeKnowledge/Exposure in data modeling with OLAP (Optional)\n\n\nAbout Business Unit\n\nIBM Consulting is IBM’s consulting and global professional services business, with market leading capabilities in business and technology transformation. With deep expertise in many industries, we offer strategy, experience, technology, and operations services to many of the most innovative and valuable companies in the world. Our people are focused on accelerating our clients’ businesses through the power of collaboration. We believe in the power of technology responsibly used to help people, partners and the planet.\n\nThis job requires you to be fully COVID-19 vaccinated prior to your start date and proof of vaccination status will be required before your start date. During the Onboarding process you will be asked to confirm your vaccination status, in case you are unable to get vaccinated for any reason, you can let us know at that stage. Please let us know if you are unable to be vaccinated due to medical or religious reasons. IBM will consider such requests on a case by case basis subject to submission of required proof by the candidate before a stipulated date.\n\nYour Life @ IBM\n\nIn a world where technology never stands still, we understand that, dedication to our clients success, innovation that matters, and trust and personal responsibility in all our relationships, lives in what we do as IBMers as we strive to be the catalyst that makes the world work better.\n\nBeing an IBMer means you’ll be able to learn and develop yourself and your career, you’ll be encouraged to be courageous and experiment everyday, all whilst having continuous trust and support in an environment where everyone can thrive whatever their personal or professional background.\n\nOur IBMers are growth minded, always staying curious, open to feedback and learning new information and skills to constantly transform themselves and our company. They are trusted to provide on-going feedback to help other IBMers grow, as well as collaborate with colleagues keeping in mind a team focused approach to include different perspectives to drive exceptional outcomes for our customers. The courage our IBMers have to make critical decisions everyday is essential to IBM becoming the catalyst for progress, always embracing challenges with resources they have to hand, a can-do attitude and always striving for an outcome focused approach within everything that they do.\n\nAre you ready to be an IBMer?\n\nAbout IBM\n\nIBM’s greatest invention is the IBMer. We believe that through the application of intelligence, reason and science, we can improve business, society and the human condition, bringing the power of an open hybrid cloud and AI strategy to life for our clients and partners around the world.\n\nRestlessly reinventing since 1911, we are not only one of the largest corporate organizations in the world, we’re also one of the biggest technology and consulting employers, with many of the Fortune 50 companies relying on the IBM Cloud to run their business.\n\nAt IBM, we pride ourselves on being an early adopter of artificial intelligence, quantum computing and blockchain. Now it’s time for you to join us on our journey to being a responsible technology innovator and a force for good in the world.\n\nLocation Statement\n\nWhen applying to jobs of your interest, we recommend that you do so for those that match your experience and expertise. Our recruiters advise that you apply to not more than 3 roles in a year for the best candidate experience.\n\nFor additional information about location requirements, please discuss with the recruiter following submission of your application.\n\nBeing You @ IBM\n\nIBM is committed to creating a diverse environment and is proud to be an equal-opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, gender, gender identity or expression, sexual orientation, national origin, caste, genetics, pregnancy, disability, neurodivergence, age, veteran status, or other characteristics. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.""}","{'employment_type': None, 'seniority_level': None, 'job_functions': [], 'industries': [], 'remote_work_allowed': False, 'job_description': {'description': ""Introduction\n\nIn this role, you'll work in one of our IBM Consulting Client Innovation Centers (Delivery Centers), where we deliver deep technical and industry expertise to a wide range of public and private sector clients around the world. Our delivery centers offer our clients locally based skills and technical expertise to drive innovation and adoption of new technology.\n\nA career in IBM Consulting is rooted by long-term relationships and close collaboration with clients across the globe.\n\nYou'll work with visionaries across multiple industries to improve the hybrid cloud and AI journey for the most innovative and valuable companies in the world. Your ability to accelerate impact and make meaningful change for your clients is enabled by our strategic partner ecosystem and our robust technology platforms across the IBM portfolio; including Software and Red Hat.\n\nCuriosity and a constant quest for knowledge serve as the foundation to success in IBM Consulting. In your role, you'll be encouraged to challenge the norm, investigate ideas outside of your role, and come up with creative solutions resulting in ground breaking impact for a wide network of clients. Our culture of evolution and empathy centers on long-term career growth and development opportunities in an environment that embraces your unique skills and experience.\n\nYour Role and Responsibilities\n\n\nUnderstand a data warehousing solution and able to work independently in such an environmentResponsible in Project development and delivery experience of a few good size projects\n\n\nRequired Technical and Professional Expertise\n\n\nFirst and most important – Sound understanding of data structures & SQL concepts and experience in writing complex SQL especially around OLAP systemsSound knowledge of the ETL tool like informatica, 5+ years of experience, Big Data technologies’ like Hadoop ecosystem, its various components, along with different tools including Spark, Hive, Sqoop,etc..In-depth knowledge of MPP/distributed systems\n\n\nPreferred Technical And Professional Expertise\n\n\nThe ability to write precise, scalable, and high-performance codeThe ability to write precise, scalable, and high-performance codeKnowledge/Exposure in data modeling with OLAP (Optional)\n\n\nAbout Business Unit\n\nIBM Consulting is IBM’s consulting and global professional services business, with market leading capabilities in business and technology transformation. With deep expertise in many industries, we offer strategy, experience, technology, and operations services to many of the most innovative and valuable companies in the world. Our people are focused on accelerating our clients’ businesses through the power of collaboration. We believe in the power of technology responsibly used to help people, partners and the planet.\n\nThis job requires you to be fully COVID-19 vaccinated prior to your start date and proof of vaccination status will be required before your start date. During the Onboarding process you will be asked to confirm your vaccination status, in case you are unable to get vaccinated for any reason, you can let us know at that stage. Please let us know if you are unable to be vaccinated due to medical or religious reasons. IBM will consider such requests on a case by case basis subject to submission of required proof by the candidate before a stipulated date.\n\nYour Life @ IBM\n\nIn a world where technology never stands still, we understand that, dedication to our clients success, innovation that matters, and trust and personal responsibility in all our relationships, lives in what we do as IBMers as we strive to be the catalyst that makes the world work better.\n\nBeing an IBMer means you’ll be able to learn and develop yourself and your career, you’ll be encouraged to be courageous and experiment everyday, all whilst having continuous trust and support in an environment where everyone can thrive whatever their personal or professional background.\n\nOur IBMers are growth minded, always staying curious, open to feedback and learning new information and skills to constantly transform themselves and our company. They are trusted to provide on-going feedback to help other IBMers grow, as well as collaborate with colleagues keeping in mind a team focused approach to include different perspectives to drive exceptional outcomes for our customers. The courage our IBMers have to make critical decisions everyday is essential to IBM becoming the catalyst for progress, always embracing challenges with resources they have to hand, a can-do attitude and always striving for an outcome focused approach within everything that they do.\n\nAre you ready to be an IBMer?\n\nAbout IBM\n\nIBM’s greatest invention is the IBMer. We believe that through the application of intelligence, reason and science, we can improve business, society and the human condition, bringing the power of an open hybrid cloud and AI strategy to life for our clients and partners around the world.\n\nRestlessly reinventing since 1911, we are not only one of the largest corporate organizations in the world, we’re also one of the biggest technology and consulting employers, with many of the Fortune 50 companies relying on the IBM Cloud to run their business.\n\nAt IBM, we pride ourselves on being an early adopter of artificial intelligence, quantum computing and blockchain. Now it’s time for you to join us on our journey to being a responsible technology innovator and a force for good in the world.\n\nLocation Statement\n\nWhen applying to jobs of your interest, we recommend that you do so for those that match your experience and expertise. Our recruiters advise that you apply to not more than 3 roles in a year for the best candidate experience.\n\nFor additional information about location requirements, please discuss with the recruiter following submission of your application.\n\nBeing You @ IBM\n\nIBM is committed to creating a diverse environment and is proud to be an equal-opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, gender, gender identity or expression, sexual orientation, national origin, caste, genetics, pregnancy, disability, neurodivergence, age, veteran status, or other characteristics. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.""}, 'job_url': {'com.linkedin.voyager.jobs.OffsiteApply': {'applyStartersPreferenceVoid': True, 'companyApplyUrl': 'https://IBM.contacthr.com/139755498?Codes=SN_LinkedIn', 'inPageOffsiteApply': False}}}","{'company_name': 'IBM', 'company_url': 'https://www.linkedin.com/company/ibm'}","{'technical_skills': [], 'other_skills': [], 'soft_skills': []}"
2,SQL or Python Developer,AKS ProTalent,India,True,"{'description': 'We are searching for an innovative, tech-savvy SQL or Python developer to create and maintain storage frameworks. To this end, the SQL or Python developer should elucidate the intended use of each database, proceed to design appropriate solutions, and then ensure the rollout of these systems. You should also be available to address queries related to the use of each database. To be successful as a SQL or Python developer, you should create robust solutions that are impervious to hacking and other security breaches. A top-notch SQL or Python developer will resolve all performance-related issues as they occur.\nResponsibilities:Gathering all salient information regarding the intended functions of each database.Receiving requests pertaining to the layout, appearance, and special features of each database.Designing and creating appropriate frameworks that are sufficiently large.Configuring databases such that they are able to withstand attacks and the loss of information.Reviewing each development to detect and amend coding and typographical errors, as well as bugs.Formulating data dictionaries that are congruent with task specifications.Creating technical documents that outline the purpose, capacity, and guidelines attached to each database.Providing practical guidance on the use and migration of each database.Servicing and updating databases, as required.\nRequirements:Degree in information technology, computer science, or an adjacent field.Certificate in Database Development is strongly advantageous.Demonstrable experience as a database developer.Portfolio of previous developments is preferred.Advanced proficiency in SQL, C++, or Java, with a preference for more than one of these.Exceptional critical thinking and troubleshooting abilities.Ability to craft detailed technical manuals.Accommodating and patient.'}","{'employment_type': None, 'seniority_level': None, 'job_functions': [], 'industries': [], 'remote_work_allowed': True, 'job_description': {'description': 'We are searching for an innovative, tech-savvy SQL or Python developer to create and maintain storage frameworks. To this end, the SQL or Python developer should elucidate the intended use of each database, proceed to design appropriate solutions, and then ensure the rollout of these systems. You should also be available to address queries related to the use of each database. To be successful as a SQL or Python developer, you should create robust solutions that are impervious to hacking and other security breaches. A top-notch SQL or Python developer will resolve all performance-related issues as they occur.\nResponsibilities:Gathering all salient information regarding the intended functions of each database.Receiving requests pertaining to the layout, appearance, and special features of each database.Designing and creating appropriate frameworks that are sufficiently large.Configuring databases such that they are able to withstand attacks and the loss of information.Reviewing each development to detect and amend coding and typographical errors, as well as bugs.Formulating data dictionaries that are congruent with task specifications.Creating technical documents that outline the purpose, capacity, and guidelines attached to each database.Providing practical guidance on the use and migration of each database.Servicing and updating databases, as required.\nRequirements:Degree in information technology, computer science, or an adjacent field.Certificate in Database Development is strongly advantageous.Demonstrable experience as a database developer.Portfolio of previous developments is preferred.Advanced proficiency in SQL, C++, or Java, with a preference for more than one of these.Exceptional critical thinking and troubleshooting abilities.Ability to craft detailed technical manuals.Accommodating and patient.'}, 'job_url': {'com.linkedin.voyager.jobs.ComplexOnsiteApply': {'unifyApplyEnabled': True, 'easyApplyUrl': 'https://www.linkedin.com/job-apply/3961137711'}}}","{'company_name': 'AKS ProTalent', 'company_url': 'https://www.linkedin.com/company/aksprotalent'}","{'technical_skills': [], 'other_skills': [], 'soft_skills': []}"
3,Interesting Job Opportunity: Data Engineer - Python/Big Data,HuQuo,"Pune, Maharashtra, India",False,"{'description': 'Basic Understanding Of\n\n Scheduling and workflow management & working experience in either ADF, Informatica, Airflow, or Similar Enterprise Data Modelling and Semantic Modelling & working experience in ERwin, ER/Studio, PowerDesigner, or Similar Logical/Physical model on Big Data sets or modern data warehouse & working experience in ERwin, ER/Studio, PowerDesigner, or Similar Agile Process (Scrum cadences, Roles, deliverables) & basic understanding in either Azure DevOps, JIRA, or Similar Architecture and data modeling for Data Lake on cloud & working experience in Amazon WebServices (AWS), Microsoft Azure, Google Cloud Platform (GCP) Basic understanding of Build and Release management & working experience in Azure DevOps, AWS CodeCommitt, or Similar\n\nStrong In\n\n Writing code in programming language & working experience in Python, PySpakrk, Scala or Similar Big Data Framework & working experience in Spark or Hadoop or Hive (incl. derivatives like pySpark (preferred), SparkScala or SparkSQL) or Similar Data warehouse working experience of concepts and development using SQL on single (SQL Server, Oracle or Similar) and parallel platforms (Azure SQL Data Warehouse or Snowflake) Code Management & working experience in GIT Hub, Azure DevOps, or Similar End to End Architecture and ETL processes & working experience in ETL Tool or Similar Reading Data Formats & working experience in JSON, XML, or Similar Data integration processes (batch & real- time) using tools & working experience in either Informatica PowerCenter and/or Cloud, Microsoft SSIS, MuleSoft, DataStage, Sqoop, or Similar Writing requirement, functional & technical documentation & working experience in the Integration design document, architecture documentation, data testing plans or Similar SQL queries & working experience in SQL code or Stored Procedures or Functions or Views or Similar Database & working experience in any of the database like MS SQL, Oracle, or Similar Analytical Problem- Solving skills & working experience in resolving complex problems or Similar Communication (read & write in English), Collaboration & Presentation skills & working experience as a team player or Similar.\n\nGood To Have\n\n Stream Processing & working experience in either Databricks Streaming, Azure Stream Analytics or HD Insight or Kinesis Data Analytics or Similar Analytical Warehouse & working experience in either SQL Data Warehouse or Amazon Athena or AWS Redshift or Big Query or Similar Real- Time Store & working experience in either Azure Cosmos DB or Amazon Dynamo- DB or Cloud Bigdata or Similar Batch Ingestion & working experience in Data Factory or Amazon Kinesis or Lambda or Cloud Pub/Sub or Similar Storage & working experience in Azure Data Lake Storage GEN1/GEN2 or Amazon S3 or Cloud Storage or Similar Batch Data Processing & working experience in either Azure Databricks or HD Insight or Amazon EMR or AWS Glue or Similar Orchestration & working experience in either Data Factory or HDInsight or Data Pipeline or Cloud composer or Similar\n\n(ref:hirist.tech)'}","{'employment_type': None, 'seniority_level': None, 'job_functions': [], 'industries': [], 'remote_work_allowed': False, 'job_description': {'description': 'Basic Understanding Of\n\n Scheduling and workflow management & working experience in either ADF, Informatica, Airflow, or Similar Enterprise Data Modelling and Semantic Modelling & working experience in ERwin, ER/Studio, PowerDesigner, or Similar Logical/Physical model on Big Data sets or modern data warehouse & working experience in ERwin, ER/Studio, PowerDesigner, or Similar Agile Process (Scrum cadences, Roles, deliverables) & basic understanding in either Azure DevOps, JIRA, or Similar Architecture and data modeling for Data Lake on cloud & working experience in Amazon WebServices (AWS), Microsoft Azure, Google Cloud Platform (GCP) Basic understanding of Build and Release management & working experience in Azure DevOps, AWS CodeCommitt, or Similar\n\nStrong In\n\n Writing code in programming language & working experience in Python, PySpakrk, Scala or Similar Big Data Framework & working experience in Spark or Hadoop or Hive (incl. derivatives like pySpark (preferred), SparkScala or SparkSQL) or Similar Data warehouse working experience of concepts and development using SQL on single (SQL Server, Oracle or Similar) and parallel platforms (Azure SQL Data Warehouse or Snowflake) Code Management & working experience in GIT Hub, Azure DevOps, or Similar End to End Architecture and ETL processes & working experience in ETL Tool or Similar Reading Data Formats & working experience in JSON, XML, or Similar Data integration processes (batch & real- time) using tools & working experience in either Informatica PowerCenter and/or Cloud, Microsoft SSIS, MuleSoft, DataStage, Sqoop, or Similar Writing requirement, functional & technical documentation & working experience in the Integration design document, architecture documentation, data testing plans or Similar SQL queries & working experience in SQL code or Stored Procedures or Functions or Views or Similar Database & working experience in any of the database like MS SQL, Oracle, or Similar Analytical Problem- Solving skills & working experience in resolving complex problems or Similar Communication (read & write in English), Collaboration & Presentation skills & working experience as a team player or Similar.\n\nGood To Have\n\n Stream Processing & working experience in either Databricks Streaming, Azure Stream Analytics or HD Insight or Kinesis Data Analytics or Similar Analytical Warehouse & working experience in either SQL Data Warehouse or Amazon Athena or AWS Redshift or Big Query or Similar Real- Time Store & working experience in either Azure Cosmos DB or Amazon Dynamo- DB or Cloud Bigdata or Similar Batch Ingestion & working experience in Data Factory or Amazon Kinesis or Lambda or Cloud Pub/Sub or Similar Storage & working experience in Azure Data Lake Storage GEN1/GEN2 or Amazon S3 or Cloud Storage or Similar Batch Data Processing & working experience in either Azure Databricks or HD Insight or Amazon EMR or AWS Glue or Similar Orchestration & working experience in either Data Factory or HDInsight or Data Pipeline or Cloud composer or Similar\n\n(ref:hirist.tech)'}, 'job_url': {'com.linkedin.voyager.jobs.OffsiteApply': {'applyStartersPreferenceVoid': False, 'companyApplyUrl': 'https://www.hirist.tech/j/data-engineer-pythonbig-data-3-6-yrs-1352474.html?utm_source=LinkedIn&utm_medium=listing&utm_campaign=linkedin_apply_ref&ref=linkedin', 'inPageOffsiteApply': False}}}","{'company_name': 'HuQuo', 'company_url': 'https://www.linkedin.com/company/huquo-consulting-pvt.-ltd.'}","{'technical_skills': [], 'other_skills': [], 'soft_skills': []}"
4,Interesting Job Opportunity: Big Data Engineer/Manager - ETL/Python,HuQuo,"Pune, Maharashtra, India",False,"{'description': 'Job Description\n\nMust Have :\n\nTech savvy engineer - willing and able to learn new skills, track industry trend.\n\n 5 - 7 years of total experience of solid data engineering experience, especially in Open Source, data-intensive, distributed environments with minimum 5 years of experience in big data related technologies like Spark, Hive, HBase, Hadoop, etc. Programming background - Mandatory- Scala, Spark and Java / Python Experience in following technologies - MapReduce, HDFS, YARN, Spark Streaming. Experience in creating e2e pipelines in Hadoop. Experience in SQL, Hive and NoSQL databases Experience in Linux / Unix platform Experience of cloud design patterns Experience in Jenkins, GitHub, Debugging the code, and error handling. Experience in Building end to end ETL Pipelines Self-starter & resourceful personality with the ability to manage pressure situations. Experience working with geographically distributed teams. Work on high- level business and technical problems, contribute to architectural decisions. Create the core framework/ templates that gives a starting point for the team members to get started with implementation/ execution.\n\nRole & Responsibilities\n\n Build Data and ETL pipelines in Hadoop. Support migration of data to the cloud using Big Data Technologies like Spark, Hive, Hadoop, Scala, Python Interact with customers daily to ensure smooth engagement. Exposure to GCP Responsible for timely and quality deliveries. Exposure to Scrum and Agile Development best practices Fulfil organization responsibilities Sharing knowledge and experience within the other groups in the organization, conducting various technical sessions and training.\n\n(ref:hirist.tech)'}","{'employment_type': None, 'seniority_level': None, 'job_functions': [], 'industries': [], 'remote_work_allowed': False, 'job_description': {'description': 'Job Description\n\nMust Have :\n\nTech savvy engineer - willing and able to learn new skills, track industry trend.\n\n 5 - 7 years of total experience of solid data engineering experience, especially in Open Source, data-intensive, distributed environments with minimum 5 years of experience in big data related technologies like Spark, Hive, HBase, Hadoop, etc. Programming background - Mandatory- Scala, Spark and Java / Python Experience in following technologies - MapReduce, HDFS, YARN, Spark Streaming. Experience in creating e2e pipelines in Hadoop. Experience in SQL, Hive and NoSQL databases Experience in Linux / Unix platform Experience of cloud design patterns Experience in Jenkins, GitHub, Debugging the code, and error handling. Experience in Building end to end ETL Pipelines Self-starter & resourceful personality with the ability to manage pressure situations. Experience working with geographically distributed teams. Work on high- level business and technical problems, contribute to architectural decisions. Create the core framework/ templates that gives a starting point for the team members to get started with implementation/ execution.\n\nRole & Responsibilities\n\n Build Data and ETL pipelines in Hadoop. Support migration of data to the cloud using Big Data Technologies like Spark, Hive, Hadoop, Scala, Python Interact with customers daily to ensure smooth engagement. Exposure to GCP Responsible for timely and quality deliveries. Exposure to Scrum and Agile Development best practices Fulfil organization responsibilities Sharing knowledge and experience within the other groups in the organization, conducting various technical sessions and training.\n\n(ref:hirist.tech)'}, 'job_url': {'com.linkedin.voyager.jobs.OffsiteApply': {'applyStartersPreferenceVoid': False, 'companyApplyUrl': 'https://www.hirist.tech/j/big-data-engineermanager-etlpython-5-7-yrs-1352466.html?utm_source=LinkedIn&utm_medium=listing&utm_campaign=linkedin_apply_ref&ref=linkedin', 'inPageOffsiteApply': False}}}","{'company_name': 'HuQuo', 'company_url': 'https://www.linkedin.com/company/huquo-consulting-pvt.-ltd.'}","{'technical_skills': [], 'other_skills': [], 'soft_skills': []}"
